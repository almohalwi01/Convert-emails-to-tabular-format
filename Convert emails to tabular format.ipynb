{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import glob # to import the email dataset forlder\n",
    "import re # to use regular expression\n",
    "import nltk # to use natural langauge prossening features\n",
    "from nltk.tokenize import word_tokenize # to split words and sentences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from collections import namedtuple\n",
    "from textblob import TextBlob # to use textblob algorthem to preprosseing the data and to get sentement of the email\n",
    "from nltk import ne_chunk, pos_tag # to use part of speech tagging\n",
    "from nltk.tree import Tree\n",
    "from pprint import pprint # to print the output in orgnazied way\n",
    "import json\n",
    "import rake\n",
    "import summarizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_dic ='emails_datasetNEW_s/*'\n",
    "fields =('Sentiment','keyWord1','KeyWord2','KeyWord3','summary','EmailSender','EmailReceiver','EmailCopy','URL','Date','PhoneNumber', 'entity')\n",
    "emailDTO  = namedtuple('emailDTO',fields)\n",
    "finalResult = {}\n",
    "#nlp = spacy.load('en_core_web_sm')\n",
    "f = open(\"stopword.txt\", \"r\")\n",
    "read_ = f.read()\n",
    "stop_words = read_.split(\"\\n\")\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "#this code processes unstructured email data based on 2 phases - cleansing and extraction.\n",
    "emailRX = re.compile((\"To: ([a-z0-9!#$%&'*+\\/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+\\/=?^_`\"\n",
    "                    \"{|}~-]+)*(@|\\sat\\s)(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?(\\.|\"\n",
    "                    \"\\sdot\\s))+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "all_data_lst = []\n",
    "for f in glob.glob('emails_datasetNEW/*'):\n",
    "    with open(f, 'r') as content_file:\n",
    "        content = content_file.read()\n",
    "        for word in stop_words:\n",
    "            if word in content: \n",
    "                content = content.replace(\" \"+ word + \" \", \" \")\n",
    "        #print(\"\\n\\n\\nfile : \",f,\"\\n\\n\\n\") \n",
    "        #print(content)\n",
    "        #doc = nlp(content)\n",
    "        #print(doc)\n",
    "        all_data_lst.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Word Tokenization\n",
    "tokenization_lst = []\n",
    "for cont in content:\n",
    "    tokenization_lst.append(word_tokenize(cont))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization \n",
    "lemmatization_lst = []\n",
    "for wordTokenize in tokenization_lst:\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in wordTokenize])\n",
    "    lemmatization_lst.append(lemmatized_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EvaluateSentiment\n",
    "for f in glob.glob(email_dic):\n",
    "    with open(f, 'r') as content_file:\n",
    "        content = content_file.read()\n",
    "        content = content.replace('\\n',' ').replace('\\r',' ').replace(',', ' ')\n",
    "        blob = TextBlob(content)\n",
    "        polarity =0\n",
    "        for sentence in blob.sentences:\n",
    "            polarity +=sentence.sentiment.polarity\n",
    "        if polarity<0:\n",
    "            polarity = -1\n",
    "        elif polarity>0:\n",
    "            polarity = 1\n",
    "        elif polarity == 0:\n",
    "            polarity = 0\n",
    "        finalResult[f]=emailDTO(Sentiment=polarity,keyWord1='NA',KeyWord2='NA',KeyWord3='NA',summary='NA',EmailSender='NA',URL='NA',EmailCopy='NA',Date='NA',EmailReceiver='NA', PhoneNumber='NA',entity=[])\n",
    "        #print(content.index, polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in glob.glob(email_dic):\n",
    "    with open(f, 'r') as content_file:\n",
    "        content_file.seek(540)\n",
    "        content1 = content_file.readlines()\n",
    "        contlst=[]\n",
    "        # to read just the email body\n",
    "        for i in content1:\n",
    "            if('Message-ID:' in i):\n",
    "                a=1                         \n",
    "            elif('Date:' in i):\n",
    "                a=1\n",
    "            elif('From:' in i):\n",
    "                a=1\n",
    "            elif('To:' in i):\n",
    "                a=1\n",
    "            elif('Subject:' in i):\n",
    "                a=1\n",
    "            elif('CC:' in i):\n",
    "                a=1\n",
    "            elif('Mime-Version:' in i):\n",
    "                a=1\n",
    "            elif('Content-Type:' in i):\n",
    "                a=1\n",
    "            elif('Content-Transfer-Encoding:' in i):\n",
    "                a=1\n",
    "            elif('Bcc:' in i):\n",
    "                a=1\n",
    "            elif('X-' in i):\n",
    "                a=1\n",
    "            elif('@' in i):\n",
    "                a=1\n",
    "            else:\n",
    "                contlst.append(i)\n",
    "\n",
    "        content=\" \".join(contlst)\n",
    "        content = content.replace('\\n',' ').replace('\\r',' ').replace(',', ' ')\n",
    "        rake_obj = rake.Rake(\"stopword.txt\", 3, 2, 2)\n",
    "        #Each word has at least 2 characters  #Each phrase has at most 3 words #Each keyword appears in the text at least 2 times\n",
    "        keywords = rake_obj.run(content)\n",
    "        obj=finalResult[f]\n",
    "        finalResult[f] = emailDTO(Sentiment=obj.Sentiment,keyWord1= keywords[0][0] if len(keywords)>=1 else 'NA',KeyWord2=keywords[1][0] if len(keywords) >=2 else 'NA',KeyWord3=keywords[2][0] if len(keywords) >=3 else 'NA',summary='NA',EmailSender='NA',URL='NA',EmailCopy='NA',Date='NA',EmailReceiver='NA', PhoneNumber='NA',entity=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in glob.glob(email_dic):\n",
    "    with open(f, 'r') as content_file:\n",
    "        content1 = content_file.readlines()\n",
    "        contlst=[]\n",
    "        # to read just the email body\n",
    "        for i in content1:\n",
    "            if('Message-ID:' in i):\n",
    "                a=1                         \n",
    "            elif('Date:' in i):\n",
    "                a=1\n",
    "            elif('From:' in i):\n",
    "                a=1\n",
    "            elif('To:' in i):\n",
    "                a=1\n",
    "            elif('Subject:' in i):\n",
    "                a=1\n",
    "            elif('CC:' in i):\n",
    "                a=1\n",
    "            elif('Mime-Version:' in i):\n",
    "                a=1\n",
    "            elif('Content-Type:' in i):\n",
    "                a=1\n",
    "            elif('Content-Transfer-Encoding:' in i):\n",
    "                a=1\n",
    "            elif('Bcc:' in i):\n",
    "                a=1\n",
    "            elif('X-' in i):\n",
    "                a=1\n",
    "            elif('@' in i):\n",
    "                a=1\n",
    "            else:\n",
    "                contlst.append(i)\n",
    "                \n",
    "        content=\" \".join(contlst)\n",
    "        summeryResponse  = summarizer.summarize_txt(content,1)\n",
    "        resp = 'NA'\n",
    "        obj=finalResult[f]\n",
    "        if len(summeryResponse)>=1:\n",
    "            resp = \" \".join(summeryResponse)\n",
    "        finalResult[f] = emailDTO(Sentiment=obj.Sentiment,keyWord1=obj.keyWord1,KeyWord2=obj.KeyWord2,KeyWord3=obj.KeyWord3,summary=resp,EmailSender='NA',URL='NA',EmailCopy='NA',Date='NA',EmailReceiver='NA', PhoneNumber='NA',entity=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract regex, fields\n",
    "FROMEMAILRX = re.compile(\"From: ([a-z0-9_\\.-]+@[\\da-z\\.-]+\\.[a-z\\.]{2,6})\")\n",
    "TOEMAILRX = re.compile(\"To: ([a-z0-9_\\.-]+@[\\da-z\\.-]+\\.[a-z\\.]{2,6})\")\n",
    "CCEMAILRX = re.compile(\"cc: ([a-z0-9_\\.-]+@[\\da-z\\.-]+\\.[a-z\\.]{2,6})\")\n",
    "URIRX = re.compile((\"https?://\\S+\"))\n",
    "DATERX = re.compile(\"Date: (\\w+), ([0-9]+) (\\w+) ([0-9]+)\")\n",
    "PHONERX = re.compile(\"(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4})\")\n",
    "for f in glob.glob(email_dic):\n",
    "    with open(f, 'r') as content_file:\n",
    "        content1 = content_file.readlines()\n",
    "        contlst=[]\n",
    "\n",
    "        for i in content1:\n",
    "            if('Message-ID:' in i):\n",
    "                a=1\n",
    "            elif('Mime-Version:' in i):\n",
    "                a=1\n",
    "            elif('Content-Type:' in i):\n",
    "                a=1\n",
    "            elif('Content-Transfer-Encoding:' in i):\n",
    "                a=1\n",
    "            else:\n",
    "                contlst.append(i)\n",
    "        content=\" \".join(contlst)\n",
    "        obj=finalResult[f]\n",
    "        EmailSender =re.findall(FROMEMAILRX,content)\n",
    "        URL =re.findall(URIRX,content)\n",
    "        EmailCopy = re.findall(CCEMAILRX,content)\n",
    "        Date = re.findall(DATERX,content)\n",
    "        EmailReceiver = re.findall(TOEMAILRX,content)\n",
    "        PhoneNumber = re.findall(PHONERX, content)\n",
    "        finalResult[f] = emailDTO(Sentiment=obj.Sentiment,keyWord1=obj.keyWord1,KeyWord2=obj.KeyWord2,KeyWord3=obj.KeyWord3,summary=obj.summary,EmailSender=EmailSender[-5:],URL=URL[-5:],EmailCopy=EmailCopy[-5:],Date=Date[-5:],EmailReceiver=EmailReceiver[-5:], PhoneNumber=PhoneNumber[-5:],entity=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\amahlawi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\amahlawi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\amahlawi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract entity field\n",
    "for f in glob.glob(email_dic):\n",
    "    with open(f, 'r') as content_file:\n",
    "        content_file.seek(640)\n",
    "        content = content_file.read().replace('\\n','  ')\n",
    "        obj=finalResult[f]\n",
    "        chunk = ne_chunk(pos_tag(word_tokenize(content)))\n",
    "        cont_chunk = []\n",
    "        curr_chunk = []\n",
    "        named_entities = []\n",
    "        for i in chunk:\n",
    "            if type(i) == Tree:\n",
    "                curr_chunk.append(\" \".join([token for token, pos in i.leaves()]))\n",
    "            elif curr_chunk:\n",
    "                named_entity = \" \".join(curr_chunk)\n",
    "                if named_entity not in cont_chunk:\n",
    "                    cont_chunk.append(named_entity)\n",
    "                    curr_chunk = []\n",
    "                #doc = ''\n",
    "                #for i in cont_chunk[:10]:\n",
    "                    #doc += str(i)\n",
    "                #doc1 = nlp(doc)\n",
    "                #if doc1.ents:\n",
    "                    #for ent in doc1.ents:\n",
    "                        #named = {ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_))}\n",
    "                        #named_entities.append(named)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        finalResult[f] = emailDTO(Sentiment=obj.Sentiment,keyWord1=obj.keyWord1,KeyWord2=obj.KeyWord2,KeyWord3=obj.KeyWord3,summary=obj.summary,EmailSender=obj.EmailSender,EmailReceiver=obj.EmailReceiver,EmailCopy=obj.EmailCopy,URL=obj.URL,Date=obj.Date,PhoneNumber=obj.PhoneNumber,entity=cont_chunk[:10])\n",
    "                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultMap = {}\n",
    "for key,val in finalResult.items():\n",
    "    resultMap[key] = val._asdict()\n",
    "#print (pprint(json.dumps(resultMap)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>keyWord1</th>\n",
       "      <th>KeyWord2</th>\n",
       "      <th>KeyWord3</th>\n",
       "      <th>summary</th>\n",
       "      <th>EmailSender</th>\n",
       "      <th>EmailReceiver</th>\n",
       "      <th>EmailCopy</th>\n",
       "      <th>URL</th>\n",
       "      <th>Date</th>\n",
       "      <th>PhoneNumber</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>lot</td>\n",
       "      <td>work</td>\n",
       "      <td>netco</td>\n",
       "      <td>(ii)\\tBudget (due Jan 3, 2002)\\t\\t\\t\\t\\t\\tTo b...</td>\n",
       "      <td>[louise.kitchen@enron.com]</td>\n",
       "      <td>[wes.colwell@enron.com]</td>\n",
       "      <td>[john.lavorato@enron.com]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Mon, 31, Dec, 2001)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[mitch.robinson, NETCO, Kitchen, Louise, Colwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Please execute and send\\n to:  Grande Communic...</td>\n",
       "      <td>[hunter.williams@grandecom.com]</td>\n",
       "      <td>[gthorse@keyad.com]</td>\n",
       "      <td>[k..allen@enron.com]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Tue, 11, Sep, 2001)]</td>\n",
       "      <td>[512-757-2794, 512-878-5467]</td>\n",
       "      <td>[PALLEN, Attached, Grande Communications Servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>intended recipient</td>\n",
       "      <td>wink</td>\n",
       "      <td>bid</td>\n",
       "      <td>512.505.3709\\n Fax 512.505.3711\\n \\n \\n -----O...</td>\n",
       "      <td>[richard.morgan@austinenergy.com]</td>\n",
       "      <td>[k..allen@enron.com]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Wed, 10, Oct, 2001)]</td>\n",
       "      <td>[704-1194, 512.505.3709, 512.505.3711, 713-853...</td>\n",
       "      <td>[Wink, Richard Morgan Manager, Green Building ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>copy</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>I don't know how many  pages it will be but le...</td>\n",
       "      <td>[wise.counsel@lpl.com]</td>\n",
       "      <td>[k..allen@enron.com]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Thu, 25, Oct, 2001)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>resolution center</td>\n",
       "      <td>transfer</td>\n",
       "      <td>continue</td>\n",
       "      <td>The following options are also available throu...</td>\n",
       "      <td>[no.address@enron.com]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Thu, 27, Dec, 2001)]</td>\n",
       "      <td>[888-877-7757, 800-973-6766, 713-345-4745, 888...</td>\n",
       "      <td>[Resolution Center, Toll Free, ENW, Enron Buil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentiment            keyWord1  KeyWord2  KeyWord3  \\\n",
       "index                                                      \n",
       "0              1                 lot      work     netco   \n",
       "1              1                  NA        NA        NA   \n",
       "2              1  intended recipient      wink       bid   \n",
       "3              1                copy        NA        NA   \n",
       "4              1   resolution center  transfer  continue   \n",
       "\n",
       "                                                 summary  \\\n",
       "index                                                      \n",
       "0      (ii)\\tBudget (due Jan 3, 2002)\\t\\t\\t\\t\\t\\tTo b...   \n",
       "1      Please execute and send\\n to:  Grande Communic...   \n",
       "2      512.505.3709\\n Fax 512.505.3711\\n \\n \\n -----O...   \n",
       "3      I don't know how many  pages it will be but le...   \n",
       "4      The following options are also available throu...   \n",
       "\n",
       "                             EmailSender            EmailReceiver  \\\n",
       "index                                                               \n",
       "0             [louise.kitchen@enron.com]  [wes.colwell@enron.com]   \n",
       "1        [hunter.williams@grandecom.com]      [gthorse@keyad.com]   \n",
       "2      [richard.morgan@austinenergy.com]     [k..allen@enron.com]   \n",
       "3                 [wise.counsel@lpl.com]     [k..allen@enron.com]   \n",
       "4                 [no.address@enron.com]                       []   \n",
       "\n",
       "                       EmailCopy URL                    Date  \\\n",
       "index                                                          \n",
       "0      [john.lavorato@enron.com]  []  [(Mon, 31, Dec, 2001)]   \n",
       "1           [k..allen@enron.com]  []  [(Tue, 11, Sep, 2001)]   \n",
       "2                             []  []  [(Wed, 10, Oct, 2001)]   \n",
       "3                             []  []  [(Thu, 25, Oct, 2001)]   \n",
       "4                             []  []  [(Thu, 27, Dec, 2001)]   \n",
       "\n",
       "                                             PhoneNumber  \\\n",
       "index                                                      \n",
       "0                                                     []   \n",
       "1                           [512-757-2794, 512-878-5467]   \n",
       "2      [704-1194, 512.505.3709, 512.505.3711, 713-853...   \n",
       "3                                                     []   \n",
       "4      [888-877-7757, 800-973-6766, 713-345-4745, 888...   \n",
       "\n",
       "                                                  entity  \n",
       "index                                                     \n",
       "0      [mitch.robinson, NETCO, Kitchen, Louise, Colwe...  \n",
       "1      [PALLEN, Attached, Grande Communications Servi...  \n",
       "2      [Wink, Richard Morgan Manager, Green Building ...  \n",
       "3                                                     []  \n",
       "4      [Resolution Center, Toll Free, ENW, Enron Buil...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(resultMap, orient=\"index\")\n",
    "df['index'] = df.reset_index().index\n",
    "df.set_index('index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
